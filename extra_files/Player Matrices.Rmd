---
title: "IS 590R"
output: html_document
---

```{r}
x <- c(1, 1, 1, 0, 0, -1, -1, -1, 0, 0, 
        1, 1, 1, 0, 0, -1, -1, 0, -1, 0, 
        1, 0, 0, 1, 1, -1, 0, 0, -1, -1,
        1, 0, 0, 1, 1, 0, 0, -1, -1, -1,
        0, 1, 1, 1, 0, 0, -1, -1, -1, 0,
        0, 1, 1, 0, 1, 0, -1, -1, 0, -1,
        1, 1, 1, 0, 0, 0, -1, 0, -1, -1,
        1, 1, 1, 0, 0, -1, 0, 0, -1, -1,
        0, 0, 1, 1, 1, -1, 0, 0, -1, -1,
        1, 0, 1, 1, 0, -1, -1, -1, 0, 0,
        1, 0, 0, 1, 1, 0, -1, -1, -1, 0)

# Change the data to a matrix for further manipulation
lineups <- matrix(x, nrow=11, byrow = TRUE)
transLineups <- t(lineups)

# Player interactions can be expressed in a matrix by multiplying the 
# lineups by the transpose of the lineups
playerInt <- transLineups %*% lineups

# The points differential is the difference in points, divided by number
# of possessions, and then multiplied by 100
differential <- c(40, -25, 60, 0, -30, -12.5, -12.5, -30, 50, 30, -50)

# The point differential per player can be determine by multiplying the 
# differential matrix by the lineups matrix
d <- differential %*% lineups

# The points differential per player is then turned into a 1 column matrix
# so further manipulation can be done
difPerPlayer <- matrix(d, ncol = 1)
difPerPlayer
```

```{r}

# This library lets us take the pseudo inverse of a matrix, as we cannot 
# take the inverse of a matrix that is not square, or has a determinant
# equal to 0
library(corpcor)
psPlayerInt <- pseudoinverse(playerInt)

# Multiplying the pseudo inverse by the differential per player gives us
# the values for the betas
betas <- psPlayerInt %*% difPerPlayer

# The lineups multiplied by betas gives us the predicted values for point
# differential (although the betas differ from the website output, they 
# yield the same predicted values)
predicted <- lineups %*% betas
predicted

# The above betas all sum up to zero, which seems to follow the sum to 
# zero constraints Dr. Sabin talked about previously.  This holds true
# for the fake betas as well.

# This section allows us to see what happens when we have the same betas
# as the website
y <- c(-30.5, 0, -56, 36.5, -31.75, -65.5, -38.25, 8.25, 40.5, -60.75)
desired <- matrix(y, ncol = 1)
final <- playerInt %*% desired
lineups %*% desired

# We can then determine the approximate error by taking the difference
# between the predicted values and the differentials, squaring these
# differences, summing them up, and then dividing by the degrees of 
# freedom
difference <- differential - predicted
differenceSquared <- difference ^ 2
error <- sum(differenceSquared)
error
```

```{r}
# Fake Data Section

f <- c(1, 1, 1, 1, 1, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0,
       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, -1, -1, -1, 0, -1, 0, -1, 0, 0, 0,
       1, 1, 0, 1, 0, 1, 1, 0, 0, 0, -1, -1, -1, 0, -1, 0, 0, -1, 0, 0,
       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, -1, -1, 0, -1, -1, -1, 0, 0, 0, 0,
       0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0, 0,
       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, -1, -1, -1, -1, 0, 0, 0, -1, 0,
       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, -1, 0, -1, -1, -1, 0, -1, 0, 0,
       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, -1, -1, -1, -1, 0, 0, -1, 0, 0, 0,
       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, -1, -1, 0, -1, -1, 0, 0, -1, 0, 0,
       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1, 0, 0, 0, -1)

f2 <- c(1, 1, 1, 1, 1, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0,
       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, -1, -1, -1, 0, -1, 0, -1, 0, 0, 0,
       1, 1, 0, 1, 0, 1, 1, 0, 0, 0, -1, -1, -1, 0, -1, 0, 0, -1, 0, 0,
       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, -1, -1, 0, -1, -1, -1, 0, 0, 0, 0,
       0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0, 0,
       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, -1, -1, -1, -1, 0, 0, 0, -1, 0,
       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, -1, 0, -1, -1, -1, 0, -1, 0, 0,
       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, -1, -1, -1, -1, 0, 0, -1, 0, 0, 0,
       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, -1, -1, 0, -1, -1, 0, 0, -1, 0, 0,
       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, -1, -1, -1, -1, 0, 0, 0, -1,
       
       1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, -1, -1, 0, 0, -1, -1, -1, 0, 0,
       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, -1, -1, 0, 0, -1, -1, -1, 0, 0,
       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, -1, 0, -1, -1, 0, -1, -1, 0, 0, 0,
       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0,
       1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, -1, -1, 0, -1, 0, -1, -1,
       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, -1, -1, -1, 0, -1, -1, 0, 0, 0, 0,
       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, -1, 0, -1, 0, -1, 0, -1, 0, -1, 0,
       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0,
       1, 1, 0, 1, 0, 1, 1, 0, 0, 0, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0,
       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, -1, -1, -1, -1, 0, -1, 0, 0, 0, 0)
fake <- matrix(f, ncol = 20, byrow=TRUE)
transFake <- t(fake)
fakeInt <- transFake %*% fake

fake2 <- matrix(f2, ncol = 20, byrow = TRUE)
transFake2 <- t(fake2)
fakeInt2 <- transFake2 %*% fake2

fakeDif <- c(40, -22.22, 0, 55.56, -28.57, -33.33, 0, 80, -41.67, 37.5)

fakeDif2 <- c(40, -22.22, 0, 55.56, -28.57, -33.33, 0, 80, -41.67, 37.5,
              83.33, -41.67, -12.5, -50, -50, 0, 33.33, 0, 40, 33.33)

fakeDifPerPlayer <- fakeDif %*% fake
fakeDifPerPlayer2 <- fakeDif2 %*% fake2

fakeDifPerPlayer <- matrix(fakeDifPerPlayer, ncol = 1)
psFakeInt <- pseudoinverse(fakeInt)
fakeBetas <- psFakeInt %*% fakeDifPerPlayer
fakeBetas

fakeDifPerPlayer2 <- matrix(fakeDifPerPlayer2, ncol = 1)
psFakeInt2 <- pseudoinverse(fakeInt2)
fakeBetas2 <- psFakeInt2 %*% fakeDifPerPlayer2
fakeBetas2
```


```{r}
# Ridge Regression section

# Make sure the appropriate libraries are loaded
library(tidyverse)
library(broom)
library(glmnet)

#model <- lm(differential~lineups)
lambdas <- 10^seq(3, -2, by = -.1)
fit <- glmnet(lineups, differential, alpha = 0, lambda = lambdas)
summary(fit)
cv_fit <- cv.glmnet(lineups, differential, alpha = 0, lambda = lambdas)
plot(cv_fit)
opt_lambda <- cv_fit$lambda.min
opt_lambda
```

```{r}
# My attempt at ridge regression
# ridge regression (alpha = 0)
#set.seed(1111)
lm.ridge <- glmnet(x = lineups, y = differential, alpha = 0)

# use cross validation to pick the "best" lambda (based on MSE)
lm.ridge.cv <- cv.glmnet(x = lineups, y = differential, 
                          type.measure = "mse", alpha = 0)

# lambda.min is the value of lambda that gives minimum mean cross-validated 
# error
lm.ridge.cv$lambda.min
# lambda.1se gives the most regularized model such that error is within one 
# standard error of the minimum
#lm.ridge.cv$lambda.1se

# The two values for lambda are the same, so it doesn't matter which one we use

# coefficients (betas) using a specific lambda penalty value
coef(lm.ridge.cv, s = "lambda.min") 
#coef(lm.ridge.cv, s = "lambda.1se")
```


```{r}
library(broom)
library(ggplot2)
rapm <- lmridge(formula = differential ~ lineups, data = lambda = seq(0, 20000, 200))
r2 <- tidy(rapm)
g <- glance(rapm2)
ggplot(r2, aes(lambda, GCV)) + geom_line() + geom_vline(xintercept = g$lambdaGCV, col = "red", lty = 2)
```


```{r}
# Creating Other Games

# Randomizes the amount of stints per game
# Randomizes the amount of points per team per stint
# Randomizes the players on the court per stint
# Randomize the number of possessions
# Each row sums to zero, 1's are only in the first half, -1's are only in the second half, and the remaining numbers have to be 0
df <- read.csv("C:/Users/Brad Hymas/Desktop/testdata.csv", header = TRUE)
df
```